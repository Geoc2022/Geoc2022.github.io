<!DOCTYPE html>
<html lang="en-us"
  dir="ltr">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width">








    






<link rel="icon" type="image/ico" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="192x192" href="http://localhost:1313/android-chrome-192x192.png">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:1313/apple-touch-icon.png">

<meta name="description" content="Human-Inspired CNNs for Explainability and Efficiency"/>


<meta name="fediverse:creator" content="@geoc@mathstodon.xyz">


<title>
    
    Unboxing the Black Box | George Chemmala
    
</title>

<link rel="canonical" href="http://localhost:1313/projects/unboxing-the-blackbox/"/>

<meta property="og:url" content="http://localhost:1313/projects/unboxing-the-blackbox/">
  <meta property="og:site_name" content="George Chemmala">
  <meta property="og:title" content="Unboxing the Black Box">
  <meta property="og:description" content="Human-Inspired CNNs for Explainability and Efficiency">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="projects">
    <meta property="article:published_time" content="2025-05-09T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-05-09T00:00:00+00:00">
    <meta property="article:tag" content="Cnn">
    <meta property="article:tag" content="Explainability">
    <meta property="article:tag" content="Computer-Vision">












<link rel="stylesheet" href="/assets/combined.min.9eacf2c6b25ba662c63b1b68f4401005ade13e5da0239d3ec760d724936ac414.css" media="all">











    




</head>







<body class="auto">

  <div class="content">
    <header>
      

<div class="header">

    

    <h1 class="header-title">
        <a href="http://localhost:1313/">George Chemmala</a>
    </h1>

    <div class="header-menu">
        

        
        

        <p
            class="small ">
            <a href="/projects" >
                /projects
            </a>
        </p>
        

        <p
            class="small ">
            <a href="/stuff" >
                /stuff
            </a>
        </p>
        

        <p
            class="small ">
            <a href="/about" >
                /about
            </a>
        </p>
        
        
    </div>

    

</div>

    </header>

    <main class="main">
      




<div class="breadcrumbs"><a href="/">~</a><span class="breadcrumbs-separator">/</span><a href="/projects/">Projects</a><span class="breadcrumbs-separator">/</span>
        <a href="/projects/unboxing-the-blackbox/">Unboxing the Black Box</a></div>


<div >
  <article>
    <header class="single-intro-container">
        
        <h1 class="single-title">Unboxing the Black Box</h1>
        <p class="single-summary">Human-Inspired CNNs for Explainability and Efficiency</p>
        
        <div class="single-subsummary">
          
          <div>
            
            <p class="single-date">
              <time datetime="2025-05-09T00:00:00&#43;00:00">May 9, 2025</time>
            </p>
          </div>
        </div>
        
    </header>
    
    <div class="single-content">
      <p>Convolutional Neural Networks (CNNs) have become essential in computer vision, but they often function as black boxes—highly accurate, but opaque and computationally expensive. This project explores a key question:</p>
<p><strong>Can we design CNNs that are more interpretable and efficient, while maintaining competitive accuracy, by mimicking how humans focus attention?</strong></p>
<p>Inspired by human visual attention, we developed two complementary strategies aimed at improving both the <strong>efficiency</strong> and <strong>explainability</strong> of CNNs.</p>
<hr>
<h2 class="heading" id="problem">
  Problem
  <a class="anchor" href="#problem">#</a>
</h2>
<p>Humans don’t process entire scenes at once—we focus on the most informative parts. Traditional CNNs, by contrast, process full images in detail, regardless of which regions are actually relevant for the task. This approach is not only inefficient but also makes it difficult to interpret how the model reaches its decisions.</p>
<p>For example, when classifying a picture of a dog vs a cat, a human would likely focus certain areas like the ears (pointy = cat, floofy = dog), rather than the entire background.</p>
<p>











<figure class="">

    <div class="img-container" style="--w: 652; --h: 515;">
        <img loading="lazy" alt="dog" src="/projects/dog.jpg" width="652" height="515">
    </div>

    
</figure>













<figure class="">

    <div class="img-container" style="--w: 3000; --h: 2000;">
        <img loading="lazy" alt="cat" src="/projects/cat.jpg" width="3000" height="2000">
    </div>

    
</figure>

<em>Von.grzanka CC BY-SA 3.0</em></p>
<p>Our goals:</p>
<ol>
<li>Reduce the computational cost of image classification by focusing only on important regions.</li>
<li>Improve model transparency by making it clear which parts of the input influence predictions.</li>
</ol>
<hr>
<h2 class="heading" id="our-approach">
  Our Approach
  <a class="anchor" href="#our-approach">#</a>
</h2>
<p>We implemented two types of models, both inspired by how humans visually process scenes:</p>
<h3 class="heading" id="focus-based-cnns">
  Focus-Based CNNs
  <a class="anchor" href="#focus-based-cnns">#</a>
</h3>
<p>These models isolate key regions of the image and classify based on those subregions alone. We explored two variants:</p>
<ul>
<li><strong>Learned focus model</strong>: Learns salient keypoints during training and extracts patches around them.</li>
<li><strong>Corner focus model</strong>: Uses Harris corner detection to identify high-curvature points, then extracts surrounding patches.</li>
</ul>
<p>Both aim to cut down on unnecessary computation and make the decision process more interpretable.</p>
<h3 class="heading" id="attention-based-cnns">
  Attention-Based CNNs
  <a class="anchor" href="#attention-based-cnns">#</a>
</h3>
<p>These models maintain a standard CNN architecture but extract intermediate features from early and late layers to build attention maps. These maps are merged with the main features before classification, helping visualize which parts of the image the model relies on.</p>
<hr>
<h2 class="heading" id="results">
  Results
  <a class="anchor" href="#results">#</a>
</h2>
<p>We tested our models on MNIST, Fashion-MNIST, and CIFAR-10. Below are some qualitative and quantitative results:</p>
<h3 class="heading" id="sample-outputs">
  Sample Outputs
  <a class="anchor" href="#sample-outputs">#</a>
</h3>
<ul>
<li>
<p><strong>Learned Focus on MNIST</strong>












<figure class="">

    <div class="img-container" style="--w: 872; --h: 219;">
        <img loading="lazy" alt="img" src="/projects/Picture3.png" width="872" height="219">
    </div>

    
</figure>

Keypoints align with digit-defining regions, such as the curves of the number 3.</p>
</li>
<li>
<p><strong>Corner Focus on Fashion-MNIST</strong>












<figure class="">

    <div class="img-container" style="--w: 1500; --h: 500;">
        <img loading="lazy" alt="img" src="/projects/corner_on_FashionMNIST.png" width="1500" height="500">
    </div>

    
</figure>

Keypoints focus on structural parts like shoulders and sleeve ends.</p>
</li>
<li>
<p><strong>Attention on CIFAR-10</strong>












<figure class="">

    <div class="img-container" style="--w: 1592; --h: 1320;">
        <img loading="lazy" alt="img" src="/projects/attentionheatmap.png" width="1592" height="1320">
    </div>

    
</figure>

Heatmaps reveal focus on foreground objects such as animals and vehicles.</p>
</li>
</ul>
<h3 class="heading" id="performance-summary">
  Performance Summary
  <a class="anchor" href="#performance-summary">#</a>
</h3>

<div class="table-outer">
    <table>
        <thead>
            <tr>
                <th>Model</th>
                <th>MNIST</th>
                <th>Fashion-MNIST</th>
                <th>CIFAR-10</th>
                <th>Efficiency</th>
            </tr>
        </thead>
        <tbody>
            <tr>
                <td>Focus (learned)</td>
                <td>98%</td>
                <td>86%</td>
                <td>52%</td>
                <td>Medium</td>
            </tr>
            <tr>
                <td>Focus (corners)</td>
                <td>86%</td>
                <td>72%</td>
                <td>34%</td>
                <td>High</td>
            </tr>
            <tr>
                <td>Attention-based</td>
                <td>—</td>
                <td>—</td>
                <td>79%</td>
                <td>Low</td>
            </tr>
        </tbody>
    </table>
</div><ul>
<li><strong>Focus models</strong> reduce computation and improve transparency by limiting input to selected regions.</li>
<li><strong>Attention models</strong> retain high accuracy and offer insight into the model&rsquo;s decision process through visualized attention.</li>
</ul>
<p><a href="https://github.com/Geoc2022/Focus-and-Attention-Based-CNNs">











<figure class="">

    <div class="img-container" >
        <img loading="lazy" alt="GitHub" src="https://img.shields.io/badge/GitHub-%23121011.svg?logo=github&amp;logoColor=white" >
    </div>

    
</figure>
</a></p>

    </div>
  </article>

  

  

  
  

<div class="single-pagination">
    <hr />

    <div class="flexnowrap">

        <div class="single-pagination-prev">
            
            <div class="single-pagination-container-prev">
                <div class="single-pagination-text">←</div>
                <div class="single-pagination-text">
                    <a href="/projects/robust-estimation-for-the-erdos-renyi-model/">
                        Robust Estimation for the Erdős-Rényi Model
                    </a>
                </div>
            </div>
            
        </div>

        <div class="single-pagination-next">
            
            <div class="single-pagination-container-next">
                <div class="single-pagination-text">
                    <a href="/projects/vote/">
                        Cryptographic Voting with Multiple Candidates
                    </a>
                </div>
                <div class="single-pagination-text">→</div>
            </div>
            
        </div>

    </div>

    <hr />
</div>



  

  

  
  <div class="back-to-top">
    <a href="#top">
      back to top
    </a>
  </div>
  

</div>


    </main>
  </div>

  
  





    




  <footer>
    

    
    





    




    
    <p>Powered by
        <a href="https://gohugo.io/">Hugo</a>
        and
        <a href="https://github.com/tomfran/typo">tomfran/typo</a>
    </p>
    
    
    


  </footer>

  
</body>

<script src="/js/theme-switch.js"></script>
<script defer src="/js/copy-code.js"></script>
</html>
