<!DOCTYPE html>
<html lang="en-us"
  dir="ltr">

<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width">








    






<link rel="icon" type="image/ico" href="https://george.chemmala.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://george.chemmala.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://george.chemmala.com/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="192x192" href="https://george.chemmala.com/android-chrome-192x192.png">
<link rel="apple-touch-icon" sizes="180x180" href="https://george.chemmala.com/apple-touch-icon.png">

<meta name="description" content="Solving the NYT Connections using graph partitioning and word vectors"/>


<meta name="fediverse:creator" content="@geoc@mathstodon.xyz">


<title>
    
    NYT Connections Solver | George Chemmala
    
</title>

<link rel="canonical" href="https://george.chemmala.com/stuff/nyt_connections_solver/"/>

<meta property="og:url" content="https://george.chemmala.com/stuff/nyt_connections_solver/">
  <meta property="og:site_name" content="George Chemmala">
  <meta property="og:title" content="NYT Connections Solver">
  <meta property="og:description" content="Solving the NYT Connections using graph partitioning and word vectors">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="stuff">
    <meta property="article:published_time" content="2025-05-22T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-05-22T00:00:00+00:00">
    <meta property="article:tag" content="Data">
    <meta property="article:tag" content="Word-Vector">
    <meta property="article:tag" content="Spectral-Graph-Theory">












<link rel="stylesheet" href="/assets/combined.min.9eacf2c6b25ba662c63b1b68f4401005ade13e5da0239d3ec760d724936ac414.css" media="all">




      <script async src="https://www.googletagmanager.com/gtag/js?id=G-xxxxxxxxx"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-xxxxxxxxx');
        }
      </script>











    




</head>







<body class="auto">

  <div class="content">
    <header>
      

<div class="header">

    

    <h1 class="header-title">
        <a href="https://george.chemmala.com/">George Chemmala</a>
    </h1>

    <div class="header-menu">
        

        
        

        <p
            class="small ">
            <a href="/projects" >
                /projects
            </a>
        </p>
        

        <p
            class="small ">
            <a href="/stuff" >
                /stuff
            </a>
        </p>
        

        <p
            class="small ">
            <a href="/about" >
                /about
            </a>
        </p>
        
        
    </div>

    

</div>

    </header>

    <main class="main">
      




<div class="breadcrumbs"><a href="/">~</a><span class="breadcrumbs-separator">/</span><a href="/stuff/">Stuffs</a><span class="breadcrumbs-separator">/</span>
        <a href="/stuff/nyt_connections_solver/">NYT Connections Solver</a></div>


<div >
  <article>
    <header class="single-intro-container">
        
        <h1 class="single-title">NYT Connections Solver</h1>
        <p class="single-summary">Solving the NYT Connections using graph partitioning and word vectors</p>
        
        <div class="single-subsummary">
          
          <div>
            
            <p class="single-date">
              <time datetime="2025-05-22T00:00:00&#43;00:00">May 22, 2025</time>
            </p>
          </div>
        </div>
        
    </header>
    
    <div class="single-content">
      <p>Me and some friends had gotten so stuck on a NYT Connections game that we decided to draw a graph of the words on a whiteboard to see the possible connections. Immediately after drawing it we realized that we could use some of our knowledge in <a href="../../projects/spectral_graph_theory">spectral graph theory</a> to solve the game. There&rsquo;s a technique called spectral clustering that uses the eigenvalues and eigenvectors of the Laplacian matrix of a graph to find the best partitioning of the graph. We could also use the similarity between the words for the weights of the edges in the graph to improve the performance of the solver.</p>
<p>I thought it would be a fun project to implement this idea and here&rsquo;s the result with a small demo:












<figure class="">

    <div class="img-container" style="--w: 660; --h: 499;">
        <img loading="lazy" alt="graph" src="/stuff/graph1.png" width="660" height="499">
    </div>

    
</figure>
</p>
<p><em>After solving the first connection</em></p>
<p>











<figure class="">

    <div class="img-container" style="--w: 660; --h: 499;">
        <img loading="lazy" alt="graph2" src="/stuff/graph2.png" width="660" height="499">
    </div>

    
</figure>
</p>
<h2 class="heading" id="how-it-works">
  How it works:
  <a class="anchor" href="#how-it-works">#</a>
</h2>
<h3 class="heading" id="word-vectors">
  Word Vectors
  <a class="anchor" href="#word-vectors">#</a>
</h3>
<p>Words can be expressed as vectors using a technique called word vectors or word embeddings. The idea is that instead of representing words as one-hot vectors or just as strings of characters, we can represent them as vectors in a high-dimensional space, allowing us to capture some of the semantic meaning of the words. For example, the word &ldquo;king&rdquo; might be represented as a vector that is close to the vector for &ldquo;queen&rdquo;, and far away from the vector for &ldquo;car&rdquo;. Moreover, we can combine these vectors to create new vectors that represent the meaning of the combination of the words. For example, the vector for &ldquo;queen&rdquo; minus &ldquo;king&rdquo; might be close to the vector for &ldquo;women&rdquo; minus &ldquo;man&rdquo;. This allows us to better compare the words and find similarities between them. This is typically the first step to setting up data for NLP/LLM models.</p>
<p>We can use pre-trained word vectors from the <code>spacy</code> library, and we can also train our own word vectors on some data from the NYT Connections game, which should help our model to better understand what type of connections are made in the game.</p>
<h3 class="heading" id="graph-partitioning">
  Graph Partitioning
  <a class="anchor" href="#graph-partitioning">#</a>
</h3>
<p>The idea is to represent the words as a graph, where each word is a node and the edges between them are the cosine similarity between the word vectors. The goal is to partition the graph into 4 groups of 4 words each, such that the words in each group are more similar to each other than to the words in the other groups. This is done using a technique called spectral clustering, which uses the eigenvalues and eigenvectors of the Laplacian matrix of the graph to find the best partitioning of the graph.</p>
<h2 class="heading" id="results">
  Results
  <a class="anchor" href="#results">#</a>
</h2>
<h3 class="heading" id="using-the-base-word-vectors">
  Using the Base Word Vectors
  <a class="anchor" href="#using-the-base-word-vectors">#</a>
</h3>
<p>Here&rsquo;s a small demo using the text interface












<figure class="">

    <div class="img-container" style="--w: 1128; --h: 920;">
        <img loading="lazy" alt="untrained model" src="/stuff/untrained.png" width="1128" height="920">
    </div>

    
</figure>
</p>
<h3 class="heading" id="using-the-trained-word-vectors">
  Using the Trained Word Vectors
  <a class="anchor" href="#using-the-trained-word-vectors">#</a>
</h3>
<p>Here we have trained the model on the NYT Connections game data to improve the performance of the solver on more difficult games. The model is trained on the NYT Connections game data, which consists of a small number of games, so maybe more data is needed to improve the performance of the model. The training runs for a few epochs (1 minute) and then the model is used to solve the game.












<figure class="">

    <div class="img-container" style="--w: 1110; --h: 906;">
        <img loading="lazy" alt="trained model" src="/stuff/trained.png" width="1110" height="906">
    </div>

    
</figure>
</p>

    </div>
  </article>

  

  

  
  

<div class="single-pagination">
    <hr />

    <div class="flexnowrap">

        <div class="single-pagination-prev">
            
            <div class="single-pagination-container-prev">
                <div class="single-pagination-text">‚Üê</div>
                <div class="single-pagination-text">
                    <a href="/stuff/mobius_band/">
                        Warping a Image into a Mobius Loop
                    </a>
                </div>
            </div>
            
        </div>

        <div class="single-pagination-next">
            
        </div>

    </div>

    <hr />
</div>



  

  

  
  <div class="back-to-top">
    <a href="#top">
      back to top
    </a>
  </div>
  

</div>


    </main>
  </div>

  
  





    




  <footer>
    

    
    





    




    
    <p>Powered by
        <a href="https://gohugo.io/">Hugo</a>
        and
        <a href="https://github.com/tomfran/typo">tomfran/typo</a>
    </p>
    
    
    


  </footer>

  
</body>

<script src="/js/theme-switch.js"></script>
<script defer src="/js/copy-code.js"></script>
</html>
